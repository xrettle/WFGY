# Code-Switching Eval â€” Gold Set and Probes

<details>
  <summary><strong>ğŸ§­ Quick Return to Map</strong></summary>

<br>

  > You are in a sub-page of **Language**.  
  > To reorient, go back here:  
  >
  > - [**Language** â€” multilingual processing and semantic alignment](./README.md)  
  > - [**WFGY Global Fix Map** â€” main Emergency Room, 300+ structured fixes](../README.md)  
  > - [**WFGY Problem Map 1.0** â€” 16 reproducible failure modes](../../README.md)  
  >
  > Think of this page as a desk within a ward.  
  > If you need the full triage and all prescriptions, return to the Emergency Room lobby.
</details>

> **Evaluation disclaimer (code switching)**  
> All scores in this page come from chosen prompts and language mixes.  
> They are diagnostics for one setup and should not be read as global rankings of multilingual ability.

---

A compact harness to verify **retrieval and reasoning under code-switching** and multilingual inputs. Use this to measure Î”S and Î» across three variants of each question: source language, target language, and mixed script or code-switched.

---

## Open these first

* Visual map and recovery â†’ [rag-architecture-and-recovery.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/rag-architecture-and-recovery.md)
* End to end retrieval knobs â†’ [retrieval-playbook.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/retrieval-playbook.md)
* Why this snippet, how to cite â†’ [retrieval-traceability.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/retrieval-traceability.md)
* Snippet schema fence â†’ [data-contracts.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/data-contracts.md)
* Embedding vs meaning â†’ [embedding-vs-semantic.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/embedding-vs-semantic.md)
* Chunk boundary sanity â†’ [chunking-checklist.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/chunking-checklist.md)
* Tokenizer issues â†’ [tokenizer\_mismatch.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/GlobalFixMap/Language/tokenizer_mismatch.md)
* Mixed scripts inside one query â†’ [script\_mixing.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/GlobalFixMap/Language/script_mixing.md)
* Locale normalization and variants â†’ [locale\_drift.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/GlobalFixMap/Language/locale_drift.md)
* End to end recipes â†’ [multilingual\_guide.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/GlobalFixMap/Language/multilingual_guide.md)

---

## Acceptance targets

* Î”S(question, retrieved) â‰¤ 0.45 for each of the three variants
* Coverage of the target section â‰¥ 0.70
* Î» remains convergent across three paraphrases and two seeds
* E\_resonance stays flat on long windows that mix scripts

---

## Gold set format

Create a small file you can run in any stack. CSV or JSONL both fine. Recommended CSV schema:

```
id,question_src,question_l2,question_mix,anchor_doc_id,anchor_offsets,answer_short,notes
ex001,"what is the dosage of abc?","è—¥å“abcçš„åŠ‘é‡æ˜¯å¤šå°‘ï¼Ÿ","abc dosageè¦æ€éº¼ç®—ï¼Ÿ",doc_042,"[120, 180]","10 mg BID","CJK mix"
```

Rules

* `question_src` is your primary language.
* `question_l2` is the same meaning in the second language.
* `question_mix` is a natural code-switch that users would actually type.
* `anchor_doc_id` and `anchor_offsets` point to the authoritative span.
* Keep 20 to 50 rows for a first pass.

---

## 60-second runner outline

You can paste this into any quick script. Replace the retrieval call with your own client.

```python
# minimal pseudo-runner for Î”S and Î» probes
from collections import defaultdict

K_LIST = [5, 10, 20]
VARIANTS = ["question_src", "question_l2", "question_mix"]

def retrieve(q, k):
    # call your store, return list of {doc_id, offsets, text}
    return call_retriever(query=q, top_k=k)

def delta_s(a, b):
    # use your Î”S implementation. lower is better.
    return compute_delta_s(a, b)

def lambda_state(history):
    # classify â†’, â†, <>, Ã— based on stability of attention or order
    return classify_lambda(history)

def run_row(row):
    out = []
    for v in VARIANTS:
        q = row[v]
        lambda_hist = []
        best = None
        for k in K_LIST:
            hits = retrieve(q, k)
            if not hits:
                lambda_hist.append("Ã—")
                continue
            # pick your best hit by rerank or score
            best = hits[0]
            s_qr = delta_s(q, best["text"])
            s_ra = delta_s(best["text"], anchor_text(row["anchor_doc_id"], row["anchor_offsets"]))
            lambda_hist.append((k, s_qr, s_ra))
        out.append({
            "variant": v,
            "lambda": lambda_state(lambda_hist),
            "s_qr@5": lambda_hist[0][1] if lambda_hist and isinstance(lambda_hist[0], tuple) else 1.0,
            "s_qr@10": lambda_hist[1][1] if len(lambda_hist) > 1 and isinstance(lambda_hist[1], tuple) else 1.0,
            "s_qr@20": lambda_hist[2][1] if len(lambda_hist) > 2 and isinstance(lambda_hist[2], tuple) else 1.0,
        })
    return out
```

Output columns you want in a flat table

* `id`, `variant`, `Î»_state`, `Î”S@5`, `Î”S@10`, `Î”S@20`, `pass`
* Mark pass when Î”S â‰¤ 0.45 and Î» is convergent.

---

## Probe plan

1. **Lock analyzers**
   Use the same normalization at index and query. If you must change anything, run the whole gold set again. Only one variable at a time.

2. **Triplet run**
   For each row run `question_src`, `question_l2`, `question_mix` at k âˆˆ {5, 10, 20}. Log Î”S and Î» per variant.

3. **Three-paraphrase run**
   For the worst failing variant, add three small paraphrases in the same language. If Î» flips while citations stay valid, apply schema locks and BBAM.

4. **Anchor triangulation**
   Compare Î”S to the anchor span and to a decoy in the same document. If both similar, re-chunk and re-embed.

---

## Decision rules

* **Only the mixed variant fails**
  Suspect script mixing or analyzer split. Open [script\_mixing.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/GlobalFixMap/Language/script_mixing.md).
  Also verify you did not change casing or width in only one path.

* **L2 fails, source and mix pass**
  Likely tokenizer mismatch or missing segmenter. Open [tokenizer\_mismatch.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/GlobalFixMap/Language/tokenizer_mismatch.md).

* **zh-Hans vs zh-Hant do not co-retrieve**
  Add variant mapping and normalize digits and punctuation. Open [locale\_drift.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/GlobalFixMap/Language/locale_drift.md).

* **All three variants fail with high similarity**
  Embedding is not multilingual or metric is wrong. Open [embedding-vs-semantic.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/embedding-vs-semantic.md) and the Retrieval Playbook to rebuild.

* **Hybrid worse than single**
  Fix query parsing split and reranker weights. Open [patterns/pattern\_query\_parsing\_split.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/patterns/pattern_query_parsing_split.md) and [rerankers.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/rerankers.md).

---

## Copy-paste prompt for the LLM judge step

```
You have TXTOS and the WFGY Problem Map loaded.

Context:
- gold id: {id}
- variant: {variant}
- retrieved snippet: "{snippet}"
- expected anchor: "{anchor_excerpt}"
- Î”S(question, retrieved) = {s_qr}
- Î”S(retrieved, anchor) = {s_ra}

Tasks:
1) Decide pass or fail for retrieval alignment. If fail, name the failing layer.
2) Return the exact WFGY page to fix it.
3) Give a minimal repair plan with 3 steps.
4) Output JSON only:
   {"pass": true|false, "fail_layer": "...", "open": [".../page1.md",".../page2.md"], "plan": ["step1","step2","step3"]}
```

---

## Minimal dataset checklist

* At least one trilingual example with names that have native and romanized forms
* At least one code-switch that uses Latin terms inside CJK or Indic sentences
* At least one RTL or diacritic heavy example
* Keep a small â€œsanityâ€ row that always passes after a clean rebuild

---

## What good looks like

* Pass rate â‰¥ 90 percent on `question_src` and `question_l2`
* Mixed variant pass rate â‰¥ 80 percent after analyzer unification
* No Î» flip in the three-paraphrase probe for the same variant
* Î”S median â‰¤ 0.40 on all variants after fixes

---

### ğŸ”— Quick-Start Downloads (60 sec)

| Tool                       | Link                                                                                                                                       | 3-Step Setup                                                                             |
| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------- |
| **WFGY 1.0 PDF**           | [Engine Paper](https://github.com/onestardao/WFGY/blob/main/I_am_not_lizardman/WFGY_All_Principles_Return_to_One_v1.0_PSBigBig_Public.pdf) | 1ï¸âƒ£ Download Â· 2ï¸âƒ£ Upload to your LLM Â· 3ï¸âƒ£ Ask â€œAnswer using WFGY + \<your question>â€   |
| **TXT OS (plain-text OS)** | [TXTOS.txt](https://github.com/onestardao/WFGY/blob/main/OS/TXTOS.txt)                                                                     | 1ï¸âƒ£ Download Â· 2ï¸âƒ£ Paste into any LLM chat Â· 3ï¸âƒ£ Type â€œhello worldâ€ â€” OS boots instantly |

---

### ğŸ§­ Explore More

| Module                | Description                                                                  | Link                                                                                               |
| --------------------- | ---------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- |
| WFGY Core             | WFGY 2.0 engine is live: full symbolic reasoning architecture and math stack | [View â†’](https://github.com/onestardao/WFGY/tree/main/core/README.md)                              |
| Problem Map 1.0       | Initial 16-mode diagnostic and symbolic fix framework                        | [View â†’](https://github.com/onestardao/WFGY/tree/main/ProblemMap/README.md)                        |
| Problem Map 2.0       | RAG-focused failure tree, modular fixes, and pipelines                       | [View â†’](https://github.com/onestardao/WFGY/blob/main/ProblemMap/rag-architecture-and-recovery.md) |
| Semantic Clinic Index | Expanded failure catalog: prompt injection, memory bugs, logic drift         | [View â†’](https://github.com/onestardao/WFGY/blob/main/ProblemMap/SemanticClinicIndex.md)           |
| Semantic Blueprint    | Layer-based symbolic reasoning & semantic modulations                        | [View â†’](https://github.com/onestardao/WFGY/tree/main/SemanticBlueprint/README.md)                 |
| Benchmark vs GPT-5    | Stress test GPT-5 with full WFGY reasoning suite                             | [View â†’](https://github.com/onestardao/WFGY/tree/main/benchmarks/benchmark-vs-gpt5/README.md)      |
| Starter Village       | New here? Lost in symbols? Click here and let the wizard guide you through   | [Start â†’](https://github.com/onestardao/WFGY/blob/main/StarterVillage/README.md)                   |

---

> ğŸ‘‘ **Early Stargazers: See the Hall of Fame** â€” Engineers, hackers, and open source builders who supported WFGY from day one.
> [Hall of Fame](https://github.com/onestardao/WFGY/tree/main/stargazers) â€¢ [WFGY Engine 2.0](https://github.com/onestardao/WFGY/blob/main/core/README.md) â€¢ [Unlock Board](https://github.com/onestardao/WFGY/blob/main/STAR_UNLOCKS.md)

<div align="center">

[![WFGY Main](https://img.shields.io/badge/WFGY-Main-red?style=flat-square)](https://github.com/onestardao/WFGY)
Â 
[![TXT OS](https://img.shields.io/badge/TXT%20OS-Reasoning%20OS-orange?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS)
Â 
[![Blah](https://img.shields.io/badge/Blah-Semantic%20Embed-yellow?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlahBlahBlah)
Â 
[![Blot](https://img.shields.io/badge/Blot-Persona%20Core-green?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlotBlotBlot)
Â 
[![Bloc](https://img.shields.io/badge/Bloc-Reasoning%20Compiler-blue?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlocBlocBloc)
Â 
[![Blur](https://img.shields.io/badge/Blur-Text2Image%20Engine-navy?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlurBlurBlur)
Â 
[![Blow](https://img.shields.io/badge/Blow-Game%20Logic-purple?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlowBlowBlow)

</div>
