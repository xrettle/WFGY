# Q082 · Binding problem

## 0. Header metadata

```txt
ID: Q082
Code: BH_NEURO_BINDING_L3_082
Domain: Neuroscience
Family: Neural representation and integration
Rank: S
Projection_dominance: I
Field_type: cognitive_field
Tension_type: cognitive_tension
Status: Open
Semantics: hybrid
E_level: E1
N_level: N2
Last_updated: 2026-01-30
```

---

## 0. Effective layer disclaimer

All statements in this file are made strictly at the effective layer of the Tension Universe (TU) framework.

Within this document we only:

* specify observables, fields, mismatch functionals and tension scores,
* describe counterfactual “worlds” in terms of patterns over those observables,
* outline admissible encoding classes and falsifiable experimental protocols.

We explicitly do not:

* introduce any new axiom system or core generative rules for TU,
* give an explicit mapping from raw experimental data (for example spikes or imaging signals) to internal TU fields,
* claim to solve the canonical binding problem or to settle any metaphysical questions about objects, perception or consciousness.

Whenever this file talks about “World T_bind” or “World F_bind”, it should be read as describing counterfactual patterns of effective-layer observables and tension values under specified encodings, not as asserting which type of world the universe actually instantiates.

---

## 1. Canonical problem and status

### 1.1 Canonical statement

The binding problem asks how distributed neural activity patterns that encode features such as color, shape, motion and location can be combined into unified perceptual objects and scenes that support coherent reports and actions.

At the psychological and neuroscientific levels, the problem can be phrased as:

> Under what conditions, and by what kinds of mechanisms, can a brain represent many objects and features at once without confusing which feature belongs to which object, and how are these unified perceptions related to underlying neural activity?

More explicitly, the binding problem concerns:

* How features that are processed in different cortical areas or maps can be joined into single object tokens.
* How the same neural substrate can represent several objects and their features at the same time.
* How the resulting representations support stable, reportable percepts, and what constraints are imposed by attention and capacity limits.

The problem has several sub forms, including:

* Feature binding in vision and other modalities.
* Temporal binding across time.
* Cross modal binding across different senses.
* Binding of perceptual objects to thoughts, intentions and actions.

### 1.2 Status and difficulty

Key partial understandings include:

* Psychological theories of feature integration that link binding to focused attention and spatial maps.
* Neural theories that relate binding to synchrony, oscillations and large scale neural coordination.
* More recent proposals that use information integration, predictive coding or vector like neural codes for compositional representation.

However, there is still no general and widely accepted theory that:

* Explains how binding can be robust for many objects and features under realistic noise and capacity limits.
* Shows how proposed mechanisms scale from simple laboratory tasks to real world scenes and cognition.
* Bridges local neural mechanisms and global conscious experience in a precise and testable way.

The binding problem is therefore treated here as an S rank open problem in neuroscience and cognitive science.

In this document we do not attempt to solve the canonical binding problem. We only specify an effective-layer encoding that treats it as a structured cognitive_tension problem between distributed neural features, object-level tokens and reports.

### 1.3 Role in the BlackHole project

Within the BlackHole S problem collection, Q082 plays several roles.

1. It is the central node for cognitive_tension between:

   * distributed neural feature codes, and
   * unified object and scene representations.

2. It connects the hard problem of consciousness (Q081) with:

   * neural coding principles (Q083),
   * developmental pattern formation (Q088),
   * higher social and cognitive functions (Q090 and AI related nodes).

3. It provides a template for:

   * defining effective layer observables for neural binding,
   * constructing cognitive tension scores,
   * designing falsifiable experiments that probe how unified percepts emerge from distributed neural activity.

### References

1. A. Treisman and G. Gelade, “A feature integration theory of attention”, Cognitive Psychology, 12(1), 97–136, 1980.
2. W. Singer, “Neuronal synchrony: a versatile code for the definition of relations”, Neuron, 24(1), 49–65, 1999.
3. G. Tononi and G. M. Edelman, “Consciousness and complexity”, Science, 282(5395), 1846–1851, 1998.
4. U. Neisser, “Cognition and Reality: Principles and Implications of Cognitive Psychology”, W. H. Freeman, 1976, chapters on perception and object recognition.

---

## 2. Position in the BlackHole graph

This block records how Q082 sits in the BlackHole graph among Q001 to Q125. Each edge has a one line reason that points to a component or tension type.

### 2.1 Upstream problems

These problems provide prerequisites, tools or conceptual foundations.

* Q081 (BH_NEURO_CONSCIOUS_HARD_L3_081)
  Reason: supplies the overall frame for what counts as a unified conscious experience, which binding must help implement at the cognitive_field level.

* Q083 (BH_NEURO_CODE_L3_083)
  Reason: defines constraints on neural coding that limit which binding schemes are viable for multi feature and multi object representation.

* Q088 (BH_NEURO_DEV_PATTERN_L3_088)
  Reason: explains how cortical maps and feature layouts develop, which constrains how local features can be aligned into global object maps.

### 2.2 Downstream problems

These problems reuse Q082 components or depend directly on its binding tension structure.

* Q090 (BH_NEURO_SOC_BRAIN_L3_090)
  Reason: reuses binding descriptors to model how social features and roles are assigned to distinct persons in social scenes.

* Q121 (BH_AI_ALIGNMENT_L3_121)
  Reason: uses binding tension as a prototype for how distributed internal signals must be bound into unified value and goal representations.

* Q123 (BH_AI_INTERP_L3_123)
  Reason: reuses object level binding descriptors to interpret how complex AI systems represent composite concepts.

### 2.3 Parallel problems

Parallel nodes share similar tension types but no direct component reuse.

* Q081 (BH_NEURO_CONSCIOUS_HARD_L3_081)
  Reason: both Q081 and Q082 work with cognitive_tension between distributed physical states and unified mental states, at different levels of abstraction.

* Q089 (BH_NEURO_PREDICTIVE_CODE_L3_089)
  Reason: both treat global consistency between many local prediction units and a unified perceptual hypothesis, with similar demands on coherence and conflict resolution.

### 2.4 Cross domain edges

Cross domain edges connect Q082 to problems in other domains that can reuse its components.

* Q111 (BH_PHIL_MIND_BODY_L3_111)
  Reason: uses binding descriptors as the neuroscientific part of how physical processes can correspond to unified subjects of experience.

* Q116 (BH_PHIL_MATH_FOUND_L3_116)
  Reason: conceptually reuses the idea of binding many local formal manipulations into a single mathematical object or proof.

* Q121 (BH_AI_ALIGNMENT_L3_121)
  Reason: connects neural binding of percepts with alignment style binding of preferences and goals in artificial agents.

---

## 3. Tension Universe encoding (effective layer)

All content in this block is at the effective layer. We only describe:

* state spaces,
* observables and fields,
* invariants and tension scores,
* singular sets and domain restrictions,
* admissible encoding classes and fairness constraints.

We do not describe any hidden generative rules, nor any stepwise mapping from raw spikes or imaging data to Tension Universe fields. We only assume that TU compatible encodings exist that make the observables below well defined for appropriate summaries of experimental or model data.

### 3.1 State space

We posit a state space

```txt
M_bind
```

with the following effective interpretation.

Each state `m` in `M_bind` represents a time bounded configuration with:

* distributed neural activity summaries across several regions and feature maps,
* a finite set of candidate percept tokens that could be reported as objects or scenes,
* coarse task and context variables such as attention allocation and instructions.

We do not formalize how `m` is constructed from raw measurements. We only assume that for each experimental condition there exist states `m` in `M_bind` from which the observables below are well defined.

### 3.2 Effective fields and observables

We define the following observables on `M_bind`.

1. Local feature activity

```txt
F_local(m; r, f)
```

* Inputs: state `m`, region index `r`, feature type index `f`.
* Output: nonnegative scalar summarizing the strength of feature `f` representation in region `r`.
* Interpretation: a coarse measure of how strongly a feature such as color, orientation or motion is encoded in a part of the system.

2. Percept token descriptor

```txt
O_token(m; k)
```

* Input: state `m`, token index `k` in a finite set.
* Output: descriptor of a candidate object or percept token, including a finite list of claimed features and an approximate location or label.
* Interpretation: the internal candidate for “one thing” that could be reported by the subject.

3. Coherence observable

```txt
C_coherence(m; k)
```

* Input: state `m`, token index `k`.
* Output: scalar in a fixed interval such as `[0, 1]` summarizing how coherent the distributed activity is for the features assigned to token `k`.
* Interpretation: high coherence means that the neural activity across regions that are supposed to belong to the same object shows strong coordination.

4. Feature assignment conflict observable

```txt
E_conflict(m)
```

* Input: state `m`.
* Output: nonnegative scalar that increases when:

  * the same feature appears to be assigned to multiple tokens without clear justification, or
  * a single token has mutually inconsistent feature assignments, or
  * spatial or temporal constraints are violated by the assignments.

5. Report observable

```txt
R_report(m)
```

* Input: state `m`.
* Output: finite list of reportable percept tokens and their verbal or behavioral labels, as would be measured in an experiment.
* Interpretation: the external outcome that an experimenter can record as the subject’s conscious report.

### 3.3 Binding mismatch quantities

We define two main mismatch quantities.

1. Structural binding mismatch

```txt
DeltaS_struct(m; r_level)
```

* Input: state `m`, resolution index `r_level` from a finite ordered set `{r_1, r_2, ..., r_K}`.
* Output: nonnegative scalar summarizing how well local feature activities are organized into object tokens at that resolution.
* At a given `r_level`, `DeltaS_struct` increases when:

  * features that should belong to the same object are weakly coordinated, or
  * features that should belong to different objects are spuriously coordinated, or
  * token assignments are ambiguous or unstable.

2. Report mismatch

```txt
DeltaS_report(m; r_level)
```

* Input: state `m`, resolution index `r_level`.
* Output: nonnegative scalar summarizing mismatch between:

  * the internal object tokens and feature assignments at that resolution, and
  * the actual reports in `R_report(m)`.

3. Combined binding mismatch

For each resolution index `r_level` we define:

```txt
DeltaS_bind(m; r_level) =
  w_struct * DeltaS_struct(m; r_level)
  + w_report * DeltaS_report(m; r_level)
```

where:

* `w_struct > 0`, `w_report > 0`,
* `w_struct + w_report = 1`,
* `w_struct` and `w_report` are chosen from a fixed interval such as `[0.25, 0.75]` before any experiment in a given encoding class and then held constant for all states and tasks in that class.

All three mismatch quantities are required to be finite and nonnegative on the regular domain described below.

### 3.4 Invariants

We define two effective invariants that can be compared across tasks, subjects and models.

1. Mean binding tension at a fixed resolution

```txt
I_bind_mean(m_set; r_level) =
  (1 / N) * sum over m in m_set of DeltaS_bind(m; r_level)
```

where `m_set` is a finite set of states selected under a given experimental condition, and `N` is its size.

2. Maximum tolerated binding tension band

For a given encoding class and resolution index, we define:

```txt
B_bind_max(r_level) =
  sup over admissible_normal_conditions of
  DeltaS_bind(m; r_level)
```

where the supremum is taken over a predefined finite catalogue of experimental conditions that count as normal, not over arbitrary states. This avoids dependence on uncontrolled extreme states while still providing a clear band for acceptable binding tension.

For practical use at the effective layer, `B_bind_max` is represented by a finite upper bound derived from empirical ranges or model ranges, and any derived thresholds are chosen according to the TU Tension Scale Charter.

### 3.5 Singular set and domain restrictions

Some observables are undefined or ill behaved for pathological states, for example when:

* the number of tokens becomes zero while tasks require at least one object,
* denominators used in normalization vanish,
* reports are completely missing.

We collect such cases in a singular set:

```txt
S_sing_bind =
  { m in M_bind :
    DeltaS_bind(m; r_level) is undefined
    for some r_level, or
    any required observable is not finite
  }
```

We restrict the analysis of Q082 at the effective layer to the regular set:

```txt
M_reg_bind = M_bind \ S_sing_bind
```

In experiments and model evaluations, any state that falls in `S_sing_bind` is treated as out of domain. Such states are reported separately as limitations of the chosen encoding and do not count as evidence for or against any claim about low tension or high tension binding regimes.

### 3.6 Admissible encoding classes and fairness constraints

To prevent post hoc tuning, we introduce a finite library of admissible binding encodings:

```txt
E_bind = { sync_based, attention_based,
           vector_symbolic, factorized_latent }
```

At the effective layer these names stand for fixed rules that determine:

* how `F_local`, `O_token`, `C_coherence`, `E_conflict` and `R_report` are computed from underlying data,
* which resolution indices `r_level` are available,
* the allowed range for `w_struct` and `w_report`.

Each encoding `e` in `E_bind` is intended to be fully specified, documented and open to external audit. Its libraries of feature descriptors, token formats, coherence measures, conflict criteria, resolution grids and weight ranges must be defined in advance of any test and kept stable within that test.

Fairness and stability constraints:

1. For any study or model evaluation, one encoding `e` in `E_bind` is selected using only task and data type information, not outcome information.
2. Once `e` is selected, its internal rules and the pair `(w_struct, w_report)` are fixed for that study and are not changed after seeing results.
3. All experiments that compare conditions or models within that study must use the same encoding and weight pair.
4. When cross checking across encodings, each encoding is first fixed, and comparisons are made at the level of patterns and robustness, not by tuning encodings to match desired outcomes.
5. Post hoc adjustment of encodings or weights to reduce tension on a particular test set is allowed only for exploratory analysis and must not be used to support any claim about low tension vs high tension binding regimes.
6. Choice of thresholds, bands and tension scales derived from `DeltaS_bind` must follow the TU Tension Scale Charter, including pre specification from calibration data or independent datasets whenever claims about World T_bind or World F_bind are made.

---

## 4. Tension principle for this problem

This block states how Q082 is characterized as a tension problem within Tension Universe, at the effective layer.

### 4.1 Binding tension functional

For each state `m` in `M_reg_bind` and each resolution index `r_level` we define the binding tension functional:

```txt
Tension_bind(m; r_level) = DeltaS_bind(m; r_level)
```

Using the definition in Block 3, we have:

* `Tension_bind(m; r_level) >= 0`,

* `Tension_bind(m; r_level)` is small when:

  * local feature structure and object tokens are in good agreement, and
  * internal binding structure and reports are consistent,

* `Tension_bind(m; r_level)` is large when either structural binding or report alignment is poor.

We can also define for a finite set of resolutions:

```txt
Tension_bind_total(m) =
  (1 / K) * sum over r_level of Tension_bind(m; r_level)
```

where the sum runs over the predefined set `{r_1, ..., r_K}`.

### 4.2 Low tension binding principle

At the effective layer the binding problem is framed as:

> Does there exist a biologically realistic encoding of neural activity and percept tokens such that, for normal conditions, binding tension remains within a low band across tasks and time?

More precisely, for a given admissible encoding `e` in `E_bind`, and for the catalogue of normal experimental conditions, a low tension binding regime satisfies:

```txt
For most regular states m and all r_level :
  Tension_bind(m; r_level) <= epsilon_bind(e, r_level)
```

where `epsilon_bind(e, r_level)` is a small threshold that depends on the encoding and resolution but does not grow without bound as the quality of data and analysis increases.

Thresholds `epsilon_bind(e, r_level)` are chosen or calibrated in advance, according to the TU Tension Scale Charter, and are not tuned on the same test data used to evaluate World T_bind vs World F_bind style claims.

### 4.3 High tension binding regimes

High tension binding regimes are those in which, for all encodings in `E_bind` that preserve basic biological and behavioral constraints, there exists:

```txt
delta_bind(e, r_level) > 0
```

such that for many relevant states:

```txt
Tension_bind(m; r_level) >= delta_bind(e, r_level)
```

even under conditions that count as normal in behavioral and neural terms.

In such regimes, frequent misbinding or fragmentation is effectively baked into the structure of the system, and no admissible encoding can make the observed patterns look like low tension binding without violating other constraints.

### 4.4 Relation to Q081 and other nodes

For Q082, the tension principle focuses on:

* unification of features into objects and scenes, and
* alignment between internal binding structure and reports.

Q081 then builds on Q082 by asking when a collection of bound percepts and internal states can be regarded as a unified conscious experience, whereas Q083 and Q090 reuse the same tension ideas at different scales and domains.

---

## 5. Counterfactual tension worlds

We now outline two counterfactual worlds at the effective layer:

* World T_bind: a world with robust, low tension binding.
* World F_bind: a world where binding remains high tension even under normal conditions.

These worlds are described only through patterns of observables and tension values, not through hidden generative mechanisms.

### 5.1 World T_bind (good binding world)

In World T_bind there exists at least one encoding `e` in `E_bind` such that:

1. Low typical binding tension

For the catalogue of normal conditions, for most regular states `m_T`:

```txt
Tension_bind(m_T; r_level) <= epsilon_bind(e, r_level)
```

holds for all `r_level` in the finite set, with thresholds that remain small when data quality and resolution improve.

2. Coherence and conflict patterns

* `C_coherence(m_T; k)` is high for tokens that belong to correctly bound objects.
* `C_coherence(m_T; k)` is low across tokens that correspond to distinct objects.
* `E_conflict(m_T)` is small for normal conditions and increases mainly in known illusions or heavy load tasks.

3. Report stability

* `R_report(m_T)` agrees with token level structure:

  * features claimed by `O_token(m_T; k)` match reports for that object in most cases,
  * trial to trial variability is limited and consistent with noise levels.

4. Invariants

* The mean binding tension `I_bind_mean` over normal states remains in a narrow band across comparable tasks and subjects.
* The maximum tolerated band `B_bind_max` remains within acceptable limits and does not need to be relaxed as more data are collected.

### 5.2 World F_bind (bad binding world)

In World F_bind there is no encoding `e` in `E_bind` that produces a low tension regime under realistic constraints.

1. Persistent high binding tension

For each `e` in `E_bind` there exist normal conditions and regular states `m_F` such that for some resolution index:

```txt
Tension_bind(m_F; r_level) >= delta_bind(e, r_level)
```

with `delta_bind(e, r_level)` strictly positive, and this cannot be removed without breaking biological or behavioral plausibility.

2. Misaligned coherence

* `C_coherence(m_F; k)` is often high for features that should not belong to the same object, or low for features that do belong together.
* `E_conflict(m_F)` is frequently high even in conditions that should be easy for a healthy brain.

3. Report mismatch

* `R_report(m_F)` frequently disagrees with the structure of `O_token(m_F; k)` in a way that cannot be attributed to simple noise.
* Subjects show frequent illusory conjunctions or object confusion even at modest loads.

4. Invariant behavior

* `I_bind_mean` and the empirical counterpart of `B_bind_max` drift upward as tasks and datasets become richer.
* Attempts to lower tension by changing the encoding violate other constraints, such as known physiological limits or basic coding principles.

### 5.3 Interpretive note

These counterfactual worlds do not decide which world we inhabit. They only spell out how patterns of effective layer observables and tension values would differ if binding was fundamentally robust or fundamentally fragile under the constraints captured by `E_bind` and the chosen observables.

Any World T_bind vs World F_bind classification is always made at the level of encodings and effective-layer patterns, not at the level of ultimate metaphysical truth about perception or consciousness.

---

## 6. Falsifiability and discriminating experiments

This block specifies experiments and protocols that can:

* test the coherence of the Q082 encoding,
* compare different binding encodings within `E_bind`,
* falsify specific combinations of observables and tension definitions.

They do not solve the binding problem but can rule out ineffective or inconsistent encodings at the effective layer.

In all experiments below, episodes that fall into `S_sing_bind` are treated as out-of-domain. They are excluded from tension estimation and reported separately as indications that the chosen encoding or experimental protocol does not cover those cases.

### Experiment 1: Behavioral binding stress test with illusory conjunctions

*Goal:*
Test whether the chosen `DeltaS_bind` and `Tension_bind` track behavioral binding success and failure across controlled variations in load and complexity.

*Setup:*

* Use visual search or matching tasks that involve color, shape and location features.

* Construct conditions with:

  * low load: few objects, simple features, ample time,
  * medium load: more objects or features,
  * high load: many objects, similar features and short display time.

* Collect:

  * error rates for feature conjunctions,
  * reaction times,
  * basic report patterns.

* Before data collection or analysis:

  * choose one encoding `e` in `E_bind`,
  * fix the resolution set `{r_1, ..., r_K}`,
  * fix `w_struct`, `w_report` and low/high tension thresholds according to the TU Tension Scale Charter,
  * record these choices in a pre registered analysis plan.

*Protocol:*

1. For each trial and condition, define a state `m` in `M_bind` that encodes local feature activity, candidate object tokens and reports, and discard episodes that fall in `S_sing_bind`.

2. For each regular state and a fixed resolution index `r_level`:

   * compute `DeltaS_struct(m; r_level)`,
   * compute `DeltaS_report(m; r_level)`,
   * compute `Tension_bind(m; r_level)`.

3. Group states by condition (low, medium, high load) and compute:

   * mean tension `I_bind_mean` for each group,
   * empirical relation between tension and error rate.

4. Optionally repeat the entire experiment for several encodings in `E_bind`, each with its own pre registered parameters, and compare patterns qualitatively rather than tuning encodings to fit any desired outcome.

*Metrics:*

* Correlation between `Tension_bind` and behavioral error rate.
* Differences in mean tension between low and high load conditions.
* Stability of these relations across subjects and sessions.

*Falsification conditions:*

* For a given encoding class `e`, if:

  * binding error rates rise sharply with load, but
  * `Tension_bind` stays flat or even decreases across the same conditions,

  then the combination of observables and weights in `DeltaS_bind` is considered misaligned and rejected for Q082.

* If different encodings in `E_bind` produce arbitrarily different qualitative tension patterns for the same behavioral data without a principled explanation, the current definition of `E_bind` or of the observables may be judged incoherent and in need of revision.

*Semantics implementation note:*
The experiment assumes the hybrid regime indicated in the metadata, implemented as continuous valued feature fields and coherence measures together with discrete token and report variables. All computations of `DeltaS_bind` are performed on these effective summaries, not on raw spike trains.

*Boundary note:*
Falsifying TU encoding != solving canonical statement. This experiment can rule out specific ways of encoding binding tension but does not solve the binding problem itself.

---

### Experiment 2: Multi region neural coherence and conflict mapping

*Goal:*
Assess whether the observables `C_coherence` and `E_conflict` and the resulting `Tension_bind` can distinguish correct binding from induced misbinding using multi region neural recordings.

*Setup:*

* Use tasks in which subjects view displays that can induce:

  * correct binding of features to objects, and
  * controlled misbinding, such as spatial swaps or rivalrous displays.

* Record neural activity from multiple cortical areas (for example early visual, higher visual and parietal regions) using a method that supports reasonable temporal and spatial resolution.

* Before analysis, define a fixed encoding `e` in `E_bind` together with its libraries, resolution grid and weight ranges, and document these as part of the experimental protocol.

*Protocol:*

1. For each trial, form a state `m` in `M_bind` that includes activity summaries, candidate tokens and reports, and discard any episodes in `S_sing_bind`.

2. For each regular state and resolution index:

   * compute `C_coherence(m; k)` for each token,
   * compute `E_conflict(m)`,
   * compute `Tension_bind(m; r_level)`.

3. Group trials into:

   * correct binding group, where reports match the intended object feature assignments,
   * misbinding group, where reports show feature swaps or conjunction errors.

4. Compare distributions of `Tension_bind` across these groups under encoding `e`.

*Metrics:*

* Difference in mean `Tension_bind` between correct binding and misbinding groups.
* Effect size for `E_conflict` and `C_coherence` patterns between the groups.
* Consistency of these differences across subjects.

*Falsification conditions:*

* If for encoding `e` the `Tension_bind` distributions for correct and misbinding groups are nearly identical, and this pattern persists across subjects and tasks, this encoding is considered ineffective for Q082 under the stated observables.
* If `Tension_bind` is systematically lower in misbinding conditions than in correct binding conditions for most subjects, the combination of observables and weights is considered inverted and rejected.
* If encodings in `E_bind` disagree qualitatively about which conditions are high vs low tension in ways that cannot be reconciled with known physiological or behavioral constraints, either the observable set or the encoding library needs revision.

*Semantics implementation note:*
All continuous measures such as `C_coherence` are computed from neural data treated as continuous fields or averaged signals, while object tokens and reports remain discrete. This respects the hybrid semantics indicated in the metadata.

*Boundary note:*
Falsifying TU encoding != solving canonical statement. Even a well performing encoding in this experiment does not by itself explain how binding works in all contexts.

---

## 7. AI and WFGY engineering spec

This block describes how Q082 can be used as an engineering module for AI systems within the WFGY framework, at the effective layer.

Q082 style modules treat binding structures as engineering abstractions. They do not assume that any model endowed with such modules is conscious or that its internal states have special metaphysical status. They only enforce structural constraints on how distributed internal features are bound into unified tokens and outputs.

### 7.1 Training signals

We define several training signals that can guide AI models toward better internal binding behavior.

1. `signal_binding_consistency`

   * Definition: proportional to `DeltaS_bind(m; r_level)` for states in tasks that require correct feature object binding.
   * Use: penalize internal configurations where the model’s inferred tokens and features are inconsistent with the demanded answer.

2. `signal_feature_assignment_conflict`

   * Definition: based on `E_conflict(m)` for intermediate representations that propose which features belong to which objects.
   * Use: discourage states where the same feature is assigned to multiple objects or incompatible bundles.

3. `signal_coherence_focus`

   * Definition: reward high `C_coherence(m; k)` for tokens that correspond to correct objects and lower coherence across unrelated tokens.
   * Use: encourage architectural patterns where attention or gating concentrates coherence along correct bindings.

4. `signal_report_alignment`

   * Definition: penalize mismatch between object level internal structure and generated outputs, in analogy with `DeltaS_report`.
   * Use: encourage models whose internal tokens and external text or actions are in close agreement.

### 7.2 Architectural patterns

We outline module patterns that reuse Q082 structures.

1. `BindingTensionHead`

   * Role: a head that predicts `DeltaS_bind` from internal feature maps or attention patterns.
   * Interface: inputs a snapshot of model activations for a multi object input, outputs scalar estimates of structural and report mismatch.

2. `ObjectTokenAssembler`

   * Role: module that constructs explicit object tokens from distributed features.
   * Interface: inputs feature maps or embeddings, outputs a small set of object tokens including feature assignments, which can be fed into tension calculations.

3. `TU_BindingObserver`

   * Role: generic observer that reads internal states and computes Q082 style observables such as `E_conflict`, `C_coherence` and PerceptUnityScore like metrics.
   * Interface: read only, with no need to expose how the base model computes its hidden states.

### 7.3 Evaluation harness

A basic evaluation harness for AI systems using Q082 components can proceed as follows.

1. Task selection

   * Multi object visual question answering.
   * Referring expressions with several entities (“the small red square above the large green circle”).
   * Compositional reasoning questions that require correct object feature combinations.

2. Conditions

   * Baseline: model without explicit Q082 modules.
   * TU mode: same model with BindingTensionHead and ObjectTokenAssembler, and training signals defined above.

3. Metrics

   * Task accuracy on binding sensitive questions.
   * Rate of misbinding type errors, where features or roles are swapped between objects.
   * Internal tension metrics such as mean `DeltaS_bind` and `E_conflict` across test cases.

4. Comparison

   * Compare both external performance and internal tension statistics between baseline and TU modes.
   * Inspect whether improvements (if any) align with lower binding tension and better unity of internal representations.

All internal observables used by Q082 style modules are treated in the hybrid sense specified in the metadata: continuous valued summaries for features and coherence, together with discrete object tokens and report-like labels.

### 7.4 60 second reproduction protocol

A minimal user facing protocol for experiencing Q082 effects:

* Baseline setup

  * Prompt: ask an AI model to describe a complex scene with several objects and features, then answer questions that depend on correct binding.
  * Observation: note any confusions where features are attached to the wrong objects.

* TU encoded setup

  * Prompt: same scene, but instruct the model to:

    * form explicit object tokens,
    * minimize an internal binding tension score,
    * report when binding is uncertain or unstable.

  * Observation: compare the rate of misbinding and the clarity of explanations about which features belong to which objects.

* Comparison metric

  * Simple counts of misbinding errors.
  * Qualitative rating of how clearly the model distinguishes objects and their features.
  * Optional use of internal tension estimates exposed by BindingTensionHead.

* What to log

  * Prompts, responses, and tension estimates for each scenario.
  * This allows later inspection without revealing any deeper generative rules of Tension Universe.

---

## 8. Cross problem transfer template

This block lists reusable components produced by Q082 and how they transfer to other problems. All components are defined at the effective layer. Reusing them in other problems does not require or expose any deeper TU core rules.

### 8.1 Reusable components produced by this problem

1. ComponentName: `BindingGraphDescriptor`

   * Type: field

   * Minimal interface:

     * Inputs: internal feature and token representations for a given state.
     * Output: a graph representation with nodes for features and tokens and edges for candidate bindings.

   * Preconditions:

     * The model must expose enough structure to identify feature like units and token like entities.

2. ComponentName: `PerceptUnityScore`

   * Type: functional

   * Minimal interface:

     * Inputs: `BindingGraphDescriptor`, `R_report` style summary.
     * Output: scalar in `[0, 1]` measuring how unified the percept is, where higher values indicate fewer conflicts and more coherent binding.

   * Preconditions:

     * The report format must specify which objects and features are being claimed.

3. ComponentName: `FeatureAssignmentConflictIndex`

   * Type: functional

   * Minimal interface:

     * Inputs: `O_token` descriptors and local feature summaries.
     * Output: nonnegative scalar equal or proportional to `E_conflict`.

   * Preconditions:

     * Tokens and features must be defined on compatible domains so that conflicts can be detected.

### 8.2 Direct reuse targets

1. Q081 (Hard problem of consciousness)

   * Reused components: `PerceptUnityScore`, `BindingGraphDescriptor`.
   * Why it transfers: unified conscious experience depends on how many bound percepts and internal states can be treated as one coherent scene.
   * What changes: the focus moves from single modality binding to multi modal and thought perception binding, but the unity score template remains useful.

2. Q083 (Neural coding principles)

   * Reused component: `BindingGraphDescriptor`.
   * Why it transfers: candidate coding schemes must support graphs that represent multiple objects and their features without explosive conflicts.
   * What changes: the emphasis is on coding capacity and efficiency rather than direct phenomenology.

3. Q090 (Neural basis of social cognition)

   * Reused components: `FeatureAssignmentConflictIndex`, `PerceptUnityScore`.
   * Why it transfers: social scenes require correct binding of roles, intentions and traits to specific persons, which is structurally similar to feature binding.
   * What changes: “features” become social attributes and roles, and tokens become agents rather than visual objects.

4. Q121 (AI alignment problem)

   * Reused component: `PerceptUnityScore` as an analogue of “value unity score”.
   * Why it transfers: complex agents must bind many local signals into a coherent set of preferences and goals.
   * What changes: the binding graph covers norms and objectives instead of sensor features, but the tension template is parallel.

---

## 9. TU roadmap and verification levels

This block explains how Q082 is positioned on the Tension Universe verification ladder and what the next measurable steps are.

### 9.1 Current levels

* E_level: E1

  * A coherent effective layer encoding of binding tension has been specified, including:

    * state space `M_bind`,
    * observables `F_local`, `O_token`, `C_coherence`, `E_conflict`, `R_report`,
    * mismatch quantities `DeltaS_struct`, `DeltaS_report`, `DeltaS_bind`,
    * singular set `S_sing_bind` and domain restrictions,
    * admissible encoding library `E_bind` and fairness constraints.

  * At least one concrete experiment has clear falsification conditions.

* N_level: N2

  * The narrative clearly links:

    * distributed neural activity,
    * object and scene level tokens,
    * experimental reports,
    * and the binding tension functional.

  * Counterfactual worlds have been described in a way that can be instantiated in both biological and artificial model studies.

### 9.2 Next measurable step toward E2

To move from E1 to E2 for Q082, at least one of the following should be implemented in practice.

1. A prototype analysis pipeline that, for a chosen encoding in `E_bind`, takes existing behavioral binding datasets and computes empirical `DeltaS_bind` values and `PerceptUnityScore` for each condition.
2. A model comparison study where several neural or AI architectures perform multi object tasks and Q082 style observables and tension scores are computed, with results published as open data.
3. A multi region neural recording study that tests Experiment 2 in Block 6 with pre registered encoding choice and analysis plan.

Each of these steps would provide concrete evidence that the encoding is not only internally coherent but also practically applicable and falsifiable, while remaining strictly at the effective layer and not claiming any direct solution to the canonical binding problem.

### 9.3 Long term role in the TU program

In the long term Q082 is expected to serve as:

* The central binding node that connects:

  * neural mechanisms,
  * conscious experience,
  * cognitive architecture,
  * and AI implementation.

* A template for how to express cognitive binding questions as tension problems with:

  * explicit observables,
  * well defined mismatch functionals,
  * falsifiable experimental protocols.

* A bridge between philosophical and engineering views on how many things can become “one world” for a system.

Advancing Q082 to higher E and N levels strengthens the empirical and engineering footing of its effective-layer encoding. It does not by itself provide a proof or disproof of any canonical statement about binding.

---

## 10. Elementary but precise explanation

The binding problem starts from an everyday observation.

When you look at a scene with many objects, you do not just see separate spots of color and shape. You see whole things. You see “the red square moving left” and “the blue circle staying still”. You do not usually mix up which color goes with which shape.

Inside the brain, however, different features are handled in different places. One area cares mainly about color, another about motion, another about shape. The binding problem asks how activity in all those areas can work together so that features are connected to the right objects.

In the Tension Universe view we do not try to guess the true internal mechanism in detail. Instead we ask:

* For each moment, can we describe:

  * what features are active in different parts of the brain,
  * which “object tokens” the system seems to be treating as separate things,
  * what the person actually reports seeing?

* Can we define a number, the binding tension, that is:

  * small when features and tokens match the reports well,
  * large when there are conflicts or confusions?

We build this number from two kinds of mismatch:

* how well distributed feature activity lines up with object tokens,
* how well those tokens line up with what is reported.

If a system lives in a good binding world, then for normal tasks this binding tension can be kept small most of the time. Misbindings and illusions happen, but they appear when tasks are very hard or when we deliberately design tricky displays.

If a system lives in a bad binding world, then even simple scenes produce high binding tension. Features often get attached to the wrong objects, or reports do not match what the internal structure suggests.

Q082 does not say which world our brains belong to, and it does not solve the binding problem. What it does is:

* give a clear way to talk about binding using observable quantities,
* give formulas for a binding tension score,
* and sketch experiments and AI modules that can test whether a proposed way of encoding binding makes sense.

It is a prototype for how to treat complex cognitive questions as tension problems that can be studied, compared and falsified without exposing any deeper generative rules of Tension Universe.

---

## Tension Universe effective-layer footer

This page is part of the **WFGY / Tension Universe** S-problem collection.

### Scope of claims

* The goal of this document is to specify an **effective-layer encoding** of the named problem.
* It does not claim to prove or disprove the canonical statement in Section 1.
* It does not introduce any new theorem beyond what is already established in the cited literature.
* It should not be cited as evidence that the corresponding open problem has been solved.

### Effective-layer boundary

* All objects used here (state spaces `M`, observables, invariants, tension scores, counterfactual "worlds") live at the effective layer only.
* No claims are made about the uniqueness or completeness of any TU-compatible model that might realize these structures.
* No explicit mapping is given from raw experimental data to TU fields; only the existence of TU-compatible encodings is assumed.

### Encoding, fairness, and falsifiability

* Encoding classes, parameter ranges, and tension thresholds are intended to be fully documented and open to external audit.
* Fairness constraints forbid post-hoc tuning of encodings based on test outcomes when making claims about low-tension vs high-tension regimes.
* Falsification criteria are always stated at the level of encodings and observables, not at the level of metaphysical claims about the world.

### Relation to charters

This page should be read together with the following charters:

* [TU Effective Layer Charter](../Charters/TU_EFFECTIVE_LAYER_CHARTER.md)
* [TU Encoding and Fairness Charter](../Charters/TU_ENCODING_AND_FAIRNESS_CHARTER.md)
* [TU Tension Scale Charter](../Charters/TU_TENSION_SCALE_CHARTER.md)
